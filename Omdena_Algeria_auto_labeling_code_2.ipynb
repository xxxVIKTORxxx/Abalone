{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOq73k/2E38xY+XjT2KVm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xxxVIKTORxxx/Abalone-DS/blob/main/Omdena_Algeria_auto_labeling_code_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will contain the processing code for automatical labeling the sentences from a lists within a .csv files, and saves them in a separate files as labeled because of contains a hateful words from the .txt file list, or required a manual labeling."
      ],
      "metadata": {
        "id": "SIqzPfIBxFQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dependencies\n",
        "\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "uhKqJ0ZQ6bl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading all the files into one\n",
        "\n",
        "for_processing_df = pd.DataFrame()\n",
        "listdir = os.listdir('/content/For_Processing')\n",
        "for i in range(len(listdir)):\n",
        "  for_processing = pd.read_csv(f'/content/For_Processing/{listdir[i]}')\n",
        "  for_processing_df = pd.concat([for_processing_df, for_processing])\n",
        "\n"
      ],
      "metadata": {
        "id": "7xMMn9cCxiqj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking it\n",
        "\n",
        "print(for_processing_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrFPy8Vg5Jj4",
        "outputId": "1c0c1cda-27e1-4bcd-b80b-b73eca42821c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "0     عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...    NaN\n",
            "1     عند انتصار الثورة الجزايري  الاعلام الجزايري ك...    NaN\n",
            "2     عند بالي طفلة تغني بصح من صوتو باين حنين ايواا...    NaN\n",
            "3                               عند بائع الحليب ههههههه    NaN\n",
            "4     عند تعيين عدد سالب على الدائرة   هل يمكن ان نن...    NaN\n",
            "...                                                 ...    ...\n",
            "8995                 سقسي مخترع و رب الكوره علي بن شيخ     NaN\n",
            "8996  اقامه لمده شهر لم تعجبني فندق توليب الصغير الر...    NaN\n",
            "8997  هناك افكار خاطئه في الكتاب ليست بالقليله بعض ا...    NaN\n",
            "8998  ان كان الدكتور فياض طرد من الاستديو فهذان الاث...    NaN\n",
            "8999  ملئ اخترعو الياجور وحنا في ياجوره مازالنا ثم م...    NaN\n",
            "\n",
            "[201070 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading hateful words list\n",
        "HW_check = pd.read_csv('/content/HatefulWords/HatefullWords.txt')\n",
        "print(HW_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80fbbBNR5pCT",
        "outputId": "01127213-6cf9-4243-d34c-5483a14a032a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          بمك\n",
            "0        فاشل\n",
            "1       ياسبي\n",
            "2      قهويين\n",
            "3       كلاتك\n",
            "4      بالرخس\n",
            "...       ...\n",
            "1149   قوادتك\n",
            "1150  ففرونسا\n",
            "1151  تراميهم\n",
            "1152    ترمتك\n",
            "1153    نيكهم\n",
            "\n",
            "[1154 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating DataFrames for separate saving\n",
        "\n",
        "Contains_HW = pd.DataFrame()\n",
        "Not_Contains_HW = pd.DataFrame()\n",
        "\n",
        "Contains_HW.to_csv('/content/Processed/ContainsHatefulWord/ContainsHatefulWord.csv')\n",
        "Not_Contains_HW.to_csv('/content/Processed/NotContainsHatefulWord/NotContainsHatefulWord.csv')\n"
      ],
      "metadata": {
        "id": "4itJMZnq0dv7"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing\n",
        "\n",
        "for sentence in for_processing_df.iloc[:,0]:\n",
        "  words_check = sentence.replace(\"\"\"!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\"\"\", ' ').split(' ')\n",
        "  for HW in HW_check:\n",
        "    for word in words_check:\n",
        "      if word == HW:\n",
        "        Contains_HW = pd.concat([Contains_HW, pd.DataFrame([sentence], columns=['sentences'])])\n",
        "        break\n",
        "      else:\n",
        "        Not_Contains_HW = pd.concat([Not_Contains_HW, pd.DataFrame([sentence], columns=['sentences'])])\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "RjDspSp78QYG",
        "outputId": "96a4b677-91ec-4b94-9a2e-227110a14c16"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-39ba10ecb4c9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mNot_Contains_HW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNot_Contains_HW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             new_data = concatenate_managers(\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m#  we can use np.concatenate, which is more performant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m#  than concat_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Contains_HW)\n",
        "print(Not_Contains_HW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ikf0z7XB8jX",
        "outputId": "55d395b9-4068-4d0a-a8d0-e53a3f3a8d12"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "                                            sentences\n",
            "0   عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...\n",
            "0   عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...\n",
            "0   عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...\n",
            "0   عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...\n",
            "0   عند المنفيقين ، يقولو الحرب خيداع. ماكش انتيخب...\n",
            "..                                                ...\n",
            "0   يا صاحب القناة مسمتعس واش قال حفيظ اليوم قالك ...\n",
            "0   يا صاحب القناة مسمتعس واش قال حفيظ اليوم قالك ...\n",
            "0   يا صاحب القناة مسمتعس واش قال حفيظ اليوم قالك ...\n",
            "0   يا صاحب القناة مسمتعس واش قال حفيظ اليوم قالك ...\n",
            "0   يا صاحب القناة مسمتعس واش قال حفيظ اليوم قالك ...\n",
            "\n",
            "[673749 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Contains_HW.to_csv('/content/Processed/ContainsHatefulWord/ContainsHatefulWord.csv')\n",
        "Not_Contains_HW.to_csv('/content/Processed/NotContainsHatefulWord/NotContainsHatefulWord.csv')"
      ],
      "metadata": {
        "id": "nk1xd8TmBV8q"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file is too big\n",
        "\n",
        "length = len(Not_Contains_HW)\n",
        "third_l = int(length/3)\n",
        "Not_Contains_HW_1 = Not_Contains_HW.iloc[:third_l,:]\n",
        "Not_Contains_HW_2 = Not_Contains_HW.iloc[third_l:third_l*2,:]\n",
        "Not_Contains_HW_3 = Not_Contains_HW.iloc[third_l*2:,:]\n",
        "print(len(Not_Contains_HW_1))\n",
        "print(len(Not_Contains_HW_2))\n",
        "print(len(Not_Contains_HW_3))\n",
        "\n",
        "Not_Contains_HW_1.to_csv('/content/Processed/NotContainsHatefulWord/NotContainsHatefulWord1.csv')\n",
        "Not_Contains_HW_2.to_csv('/content/Processed/NotContainsHatefulWord/NotContainsHatefulWord2.csv')\n",
        "Not_Contains_HW_3.to_csv('/content/Processed/NotContainsHatefulWord/NotContainsHatefulWord3.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWy1yABuOgUF",
        "outputId": "75412146-1567-4061-8c4f-ad95f18607a0"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66972\n",
            "66972\n",
            "66973\n"
          ]
        }
      ]
    }
  ]
}